{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "root_url = \"https://www.heise.de\"\n",
    "\n",
    "def parse_rating(rating_img):\n",
    "    if rating_img is not None:\n",
    "        return int(re.search(r'wertung_(\\d)', rating_img['src']).group(1))\n",
    "    \n",
    "def parse_response_count(_response_count):\n",
    "    if _response_count is not None:\n",
    "        return int(re.search(r'\\d+', _response_count.text.strip()).group(0))\n",
    "    \n",
    "    \n",
    "root_soup = BeautifulSoup(requests.get(root_url).text, 'html.parser')\n",
    "\n",
    "articles = root_soup.find_all(class_='a-article-teaser')\n",
    "print(len(articles), \"articles found\")\n",
    "\n",
    "# TODO: loop through articles\n",
    "\n",
    "article = articles[0]\n",
    "article_id = article['data-cid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version, sys.platform, sys.executable)\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_posting_content(_posting_url):\n",
    "    posting_soup = BeautifulSoup(requests.get(_posting_url).text, 'html.parser')\n",
    "    return posting_soup.find(class_='bbcode_v1').text.strip()\n",
    "\n",
    "\n",
    "def load_postings(_article_id):\n",
    "    article_soup = BeautifulSoup(requests.get(root_url + '/-' + str(_article_id)).text, 'html.parser')\n",
    "    comments_url = root_url + article_soup.find(class_='comment-button')['href'][:-8] + 'chronological/'\n",
    "    \n",
    "    # loop through comment pages\n",
    "    posts = []\n",
    "    _page = 1\n",
    "    while(True):\n",
    "        print(f\"fetching page {_page}...\")\n",
    "        _comments_page_url = comments_url + 'page-' + str(_page)\n",
    "        _comments_page_soup = BeautifulSoup(requests.get(_comments_page_url).text, 'html.parser')\n",
    "        _page_posts = _comments_page_soup.find_all(class_='posting_element')\n",
    "        if(len(_page_posts) > 0):\n",
    "            print(f\"found {len(_page_posts)} posts\")\n",
    "            posts = posts + _page_posts\n",
    "        else:\n",
    "            print(f\"No posts found. Exiting loop...\")\n",
    "            break\n",
    "        _page += 1\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'article_id': _article_id,\n",
    "        'article_url': root_url + '/-' + str(_article_id),\n",
    "        'article_title': article_soup.find(\"meta\", attrs={'name': 'title'})['content'].strip(),\n",
    "        'article_keywords': article_soup.find(\"meta\", attrs={'name': 'keywords'})['content'],\n",
    "        'article_comments_count': int( re.search(r'\\((\\d+)\\)', article_soup.find(class_='comment-button__text').text).group(1) ),\n",
    "        'posting_url': [p.find(class_='posting_subject')['href'] for p in posts],\n",
    "        'title': [p.find(class_='posting_subject').text.strip() for p in posts],\n",
    "        'rating': [p.find(class_='tree_thread_list--rating').img for p in posts],\n",
    "        'response_count': [p.find(class_='posting_count') for p in posts]\n",
    "    })\n",
    "    df.article_keywords = df.article_keywords.str.split(', ')\n",
    "    df['posting_id'] = df.posting_url.str.extract(r'posting-(\\d+)')\n",
    "    df['posting_url'] = r'https://www.heise.de/forum/p-' + df.posting_id\n",
    "    df['content'] = df.posting_url.map(load_posting_content)\n",
    "    \n",
    "    df.rating = df.rating.apply(parse_rating)\n",
    "    print(\"downloading posting contents...\")\n",
    "    df.response_count = df.response_count.apply(parse_response_count)\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "df = load_postings(4952130)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('heise_postings_' + str(4952130) + '.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heise-sentiment",
   "language": "python",
   "name": "heise-sentiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
